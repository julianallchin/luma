// This file was generated by [ts-rs](https://github.com/Aleph-Alpha/ts-rs). Do not edit this file manually.

export type AudioCrop = { startSeconds: number, endSeconds: number, };

/**
 * 3-band envelope data for rekordbox-style waveform rendering
 */
export type BandEnvelopes = { 
/**
 * Low frequency envelope (bass) - values 0.0-1.0
 */
low: Array<number>, 
/**
 * Mid frequency envelope (vocals/instruments) - values 0.0-1.0
 */
mid: Array<number>, 
/**
 * High frequency envelope (hats/air) - values 0.0-1.0
 */
high: Array<number>, };

export type BeatGrid = { beats: Array<number>, downbeats: Array<number>, bpm: number, downbeatOffset: number, beatsPerBar: number, };

/**
 * Input for creating a new annotation
 */
export type CreateAnnotationInput = { trackId: number, patternId: number, startTime: number, endTime: number, zIndex: number, };

export type Edge = { id: string, fromNode: string, fromPort: string, toNode: string, toPort: string, };

export type Graph = { nodes: Array<NodeInstance>, edges: Array<Edge>, };

/**
 * Context provided by the host (editor/renderer) for graph execution.
 * This separates data fetching from graph logic - the host prepares the
 * audio and timing data, and the graph simply processes it.
 */
export type GraphContext = { 
/**
 * The track ID for database lookups (stems, chord analysis, etc.)
 */
trackId: number, 
/**
 * Start time of the audio segment in seconds
 */
startTime: number, 
/**
 * End time of the audio segment in seconds
 */
endTime: number, 
/**
 * Pre-computed beat grid for the segment (already windowed to start/end)
 */
beatGrid: BeatGrid | null, };

/**
 * Snapshot of playback state sent to frontend
 */
export type HostAudioSnapshot = { 
/**
 * Whether audio is currently loaded
 */
isLoaded: boolean, 
/**
 * Whether playback is active
 */
isPlaying: boolean, 
/**
 * Current playhead position in seconds (relative to segment start, 0 to duration)
 */
currentTime: number, 
/**
 * Duration of the loaded segment in seconds
 */
durationSeconds: number, 
/**
 * Whether looping is enabled
 */
loopEnabled: boolean, };

export type MelSpec = { width: number, height: number, data: Array<number>, beatGrid: BeatGrid | null, };

export type NodeInstance = { id: string, typeId: string, params: Record<string, unknown>, positionX: number | null, positionY: number | null, };

export type NodeTypeDef = { id: string, name: string, description: string | null, category: string | null, inputs: Array<PortDef>, outputs: Array<PortDef>, params: Array<ParamDef>, };

export type ParamDef = { id: string, name: string, paramType: ParamType, defaultNumber: number | null, defaultText: string | null, };

export type ParamType = "Number" | "Text";

export type PatternDetail = { id: number, name: string, description: string | null, graphJson: string, createdAt: string, updatedAt: string, };

export type PatternSummary = { id: number, name: string, description: string | null, createdAt: string, updatedAt: string, };

export type PortDef = { id: string, name: string, portType: PortType, };

export type PortType = "Intensity" | "Audio" | "BeatGrid" | "Series" | "Color";

export type RunResult = { views: { [key in string]?: Array<number> }, seriesViews: { [key in string]?: Series }, melSpecs: { [key in string]?: MelSpec }, colorViews: { [key in string]?: string }, };

export type Series = { dim: number, labels: Array<string> | null, samples: Array<SeriesSample>, };

export type SeriesSample = { time: number, values: Array<number>, label: string | null, };

/**
 * A track annotation represents a pattern placed on a track's timeline
 */
export type TrackAnnotation = { id: number, trackId: number, patternId: number, startTime: number, endTime: number, zIndex: number, createdAt: string, updatedAt: string, };

export type TrackSummary = { id: number, trackHash: string, title: string | null, artist: string | null, album: string | null, trackNumber: number | null, discNumber: number | null, durationSeconds: number | null, filePath: string, albumArtPath: string | null, albumArtMime: string | null, albumArtData: string | null, createdAt: string, updatedAt: string, };

/**
 * Waveform data for timeline visualization
 */
export type TrackWaveform = { trackId: number, 
/**
 * Low-resolution waveform samples (min/max pairs for each bucket)
 */
previewSamples: Array<number>, 
/**
 * High-resolution waveform samples (min/max pairs for each bucket)
 */
fullSamples: Array<number> | null, 
/**
 * 3-band envelopes for full waveform (rekordbox-style)
 */
bands: BandEnvelopes | null, 
/**
 * 3-band envelopes for preview waveform
 */
previewBands: BandEnvelopes | null, 
/**
 * Legacy: Colors for each bucket in full_samples (interleaved R, G, B bytes)
 */
colors: Array<number> | null, 
/**
 * Legacy: Colors for each bucket in preview_samples (interleaved R, G, B bytes)
 */
previewColors: Array<number> | null, sampleRate: number, durationSeconds: number, };

/**
 * Input for updating an annotation
 */
export type UpdateAnnotationInput = { id: number, startTime: number | null, endTime: number | null, zIndex: number | null, };
